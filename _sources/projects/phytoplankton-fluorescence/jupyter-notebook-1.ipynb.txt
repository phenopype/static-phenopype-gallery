{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phytoplankton fluorescence and shape\n",
    "\n",
    "For a more detailed description see: <https://www.phenopype.org/gallery/projects/phytoplankton-fluorescence/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phenopype successfully imported the following plugin dependencies:\n",
      "torch\n"
     ]
    }
   ],
   "source": [
    "import phenopype as pp\n",
    "import os \n",
    "\n",
    "## my root directory - modify as you see fit \n",
    "os.chdir(r\"D:\\science\\packages\\phenopype\\phenopype-gallery_exec\")\n",
    "\n",
    "## my laptop has a small screen, so I use a smaller phenopype window\n",
    "pp._config.window_max_dim = 800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make phenopype project\n",
    "\n",
    "Create a phenopype project (remember, `Project` is used to both create new projects, and load existing ones). Different phenopype projects can be useful, e.g., to process different batches of images from field seasons, perspectives, etc,. It makes sense to create them side by side in a subfolder, which I call \"phenopype\". Thus, my research projects often have the following directory structure (just my way of working - this is really totally up to you):\n",
    "\n",
    "```\n",
    "my-project\n",
    "    data                       # processed data (e.g., tables)\n",
    "    data_raw                   # raw data (images, videos, etc.)\n",
    "    phenopype                  # phenopype projects\n",
    "    phenopype_templates        # phenopype .yaml config templates\n",
    "    scripts                    # python, R, etc.\n",
    "    [...]                      # manuscripts, figures, literature, etc.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "Creating a new phenopype project directory at:\n",
      "D:\\science\\packages\\phenopype\\phenopype-gallery_exec\\phenopype\\phytoplankton-fluorescence\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Proceed? (y/n)\n",
      " y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Project \"phytoplankton-fluorescence\" successfully created.\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "proj = pp.Project(r\"phenopype\\phytoplankton-fluorescence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "phenopype will search for image files at\n",
      "\n",
      "D:\\science\\packages\\phenopype\\phenopype-gallery_exec\\data_raw\\phytoplankton-fluorescence\n",
      "\n",
      "using the following settings:\n",
      "\n",
      "filetypes: ['jpg', 'JPG', 'jpeg', 'JPEG', 'tif', 'png', 'bmp'], include: [], exclude: FL, mode: copy, recursive: False, resize: False, unique: path\n",
      "\n",
      "Found image phyto1_BF.tif - phenopype-project folder 0__phyto1_BF created\n",
      "Found image phyto2_BF.tif - phenopype-project folder 0__phyto2_BF created\n",
      "Found image phyto3_BF.tif - phenopype-project folder 0__phyto3_BF created\n",
      "\n",
      "Found 3 files - using all\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## add all phytoplankton images from the data folder, but exclude fluorescence channels\n",
    "proj.add_files(image_dir = r\"data_raw\\phytoplankton-fluorescence\", exclude=\"FL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- template saved under D:\\science\\packages\\phenopype\\phenopype-gallery_exec\\phenopype\\phytoplankton-fluorescence\\data\\0__phyto1_BF\\pype_config_v1.yaml\n",
      "- template saved under D:\\science\\packages\\phenopype\\phenopype-gallery_exec\\phenopype\\phytoplankton-fluorescence\\data\\0__phyto2_BF\\pype_config_v1.yaml\n",
      "- template saved under D:\\science\\packages\\phenopype\\phenopype-gallery_exec\\phenopype\\phytoplankton-fluorescence\\data\\0__phyto3_BF\\pype_config_v1.yaml\n"
     ]
    }
   ],
   "source": [
    "## add the config template; provide a tag\n",
    "proj.add_config(template_path=r\"phenopype_templates\\phytoplankton-fluorescence_template1.yaml\", tag=\"v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../_assets/images/phytoplankton-fluorescence_edit_contours.gif\n",
    "---\n",
    "width: 600px\n",
    "align: center\n",
    "---\n",
    "Use the `edit_contour` function to remove unwanted objects, e.g. cells that are broken, too small, or other unwanted junk and detritus.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUTOLOAD\n",
      " - nothing to autoload\n",
      "Stage: add annotation control args\n",
      "Stage: add annotation control args\n",
      "Stage: add annotation control args\n",
      "Updating pype config: applying staged changes\n",
      "\n",
      "\n",
      "------------+++ new pype iteration 2022-07-29 11:45:32 +++--------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PREPROCESSING\n",
      "blur\n",
      "\n",
      "\n",
      "SEGMENTATION\n",
      "threshold\n",
      "- multichannel image supplied, converting to grayscale\n",
      "- decompose image: using gray channel\n",
      "morphology\n",
      "morphology\n",
      "detect_contour\n",
      "- found 89 contours that match criteria\n",
      "edit_contour\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "\n\nTERMINATE (by user)",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m \n\nTERMINATE (by user)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda3\\envs\\pp-dev\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3560: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "## run image processing (`window_max_dim` controls the window size of all GUI functions in the Pype config)\n",
    "for path in proj.dir_paths:\n",
    "    pp.Pype(path, tag=\"v1\", window_max_dim=1750) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute shape features of cells in brightfield images\n",
    "\n",
    "The shape features say something about cell morphology, which is why we only want intact cells. Since the fluorescence channels may not tell us whether a cell is intact or not, we only compute those features in the objects detected in the brightfield images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# phenopype gallery project 3\n",
      "# ---------------------------\n",
      "# detect phytoplankton contours\n",
      "\n",
      "config_info:\n",
      "    config_name: pype_config_v1.yaml\n",
      "    date_created: '2022-01-17 22:16:49'\n",
      "    date_last_modified:\n",
      "    template_name: gallery_project_5.yaml\n",
      "    template_path: D:\\workspace\\git-repos\\phenopype\\phenopype-templates\\templates\\gallery\\gallery_project_5.yaml\n",
      "processing_steps:\n",
      "    - preprocessing:\n",
      "        - blur:\n",
      "            kernel_size: 9\n",
      "    - segmentation:\n",
      "        - threshold:\n",
      "            method: adaptive\n",
      "            blocksize: 299\n",
      "            constant: 10\n",
      "        - morphology:\n",
      "            operation: open\n",
      "            shape: cross\n",
      "            kernel_size: 5\n",
      "            iterations: 1\n",
      "        - morphology:\n",
      "            operation: close\n",
      "            shape: ellipse\n",
      "            kernel_size: 3\n",
      "            iterations: 3\n",
      "        - detect_contour:\n",
      "            ANNOTATION: {type: contour, id: a, edit: overwrite}\n",
      "            min_area: 150\n",
      "        - edit_contour:\n",
      "            ANNOTATION: {type: drawing, id: a, edit: false}\n",
      "            overlay_blend: 0.1\n",
      "            overlay_line_width: 1\n",
      "        - detect_contour:\n",
      "            ANNOTATION: {type: contour, id: b, edit: overwrite}\n",
      "            min_area: 10\n",
      "    - visualization:\n",
      "        - select_canvas:\n",
      "            canvas: raw\n",
      "        - draw_contour\n",
      "    - measurement:\n",
      "        - compute_shape_features:\n",
      "            features: [\"basic\",\"moments\",\"hu_moments\"]\n",
      "    - export:\n",
      "        - save_canvas\n",
      "        - save_annotation:\n",
      "            overwrite: true\n",
      "\n",
      "This is what the new config may look like (can differ beteeen files) - proceed?y\n",
      "New config saved for 0__phyto1_BF\n",
      "New config saved for 0__phyto2_BF\n",
      "New config saved for 0__phyto3_BF\n"
     ]
    }
   ],
   "source": [
    "## use `edit_config`´to inject `compute_shape_features` into the configuration files\n",
    "## this makes the initial image processing faster, as this step is somehwat computationally intensive \n",
    "target1 = \"\"\"    - export:\"\"\"\n",
    "replacement1 = \"\"\"    - measurement:\n",
    "        - compute_shape_features:\n",
    "            features: [\"basic\",\"moments\",\"hu_moments\"]\n",
    "    - export:\"\"\"\n",
    "proj.edit_config(tag=\"v1\", target=target1, replacement=replacement1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format path to abspath\n",
      "- no annotation_type selected - returning all annotations\n",
      "\n",
      "AUTOLOAD\n",
      "- annotations loaded:\n",
      "{\n",
      "\"contour\": [\"a\", \"b\"],\n",
      "\"drawing\": [\"a\"]\n",
      "}\n",
      "updating pype config file\n",
      "\n",
      "\n",
      "------------+++ new pype iteration 2022-01-17 22:18:56 +++--------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PREPROCESSING\n",
      "blur\n",
      "\n",
      "\n",
      "SEGMENTATION\n",
      "threshold\n",
      "- multichannel image supplied, converting to grayscale\n",
      "- decompose image: using gray channel\n",
      "morphology\n",
      "morphology\n",
      "detect_contour\n",
      "- loaded existing annotation of type \"contour\" with ID \"a\": overwriting (edit=overwrite)\n",
      "- found 89 contours that match criteria\n",
      "edit_contour\n",
      "- loaded existing annotation of type \"drawing\" with ID \"a\": skipping (edit=False)\n",
      "detect_contour\n",
      "- loaded existing annotation of type \"contour\" with ID \"b\": overwriting (edit=overwrite)\n",
      "- found 71 contours that match criteria\n",
      "\n",
      "\n",
      "VISUALIZATION\n",
      "select_canvas\n",
      "- raw image\n",
      "draw_contour\n",
      "\n",
      "\n",
      "MEASUREMENT\n",
      "compute_shape_features\n",
      "\n",
      "\n",
      "EXPORT\n",
      "save_canvas\n",
      "- image saved under D:\\workspace\\git-repos\\phenopype\\phenopype-gallery\\_temp\\project_5\\project\\data\\0__phyto1_BF\\canvas_v1.jpg (overwritten).\n",
      "save_annotation\n",
      "- loading existing annotation file\n",
      "- updating annotation of type \"contour\" with id \"a\" in \"annotations_v1.json\" (overwrite=\"entry\")\n",
      "- updating annotation of type \"contour\" with id \"b\" in \"annotations_v1.json\" (overwrite=\"entry\")\n",
      "- updating annotation of type \"drawing\" with id \"a\" in \"annotations_v1.json\" (overwrite=\"entry\")\n",
      "- writing annotation of type \"shape_features\" with id \"a\" to \"annotations_v1.json\"\n",
      "updating pype config file\n",
      "\n",
      "\n",
      "------------+++ finished pype iteration +++--------------\n",
      "-------(End with Ctrl+Enter or re-run with Enter)--------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "AUTOSAVE\n",
      "- nothing to autosave\n",
      "Format path to abspath\n",
      "- no annotation_type selected - returning all annotations\n",
      "\n",
      "AUTOLOAD\n",
      "- annotations loaded:\n",
      "{\n",
      "\"contour\": [\"a\", \"b\"],\n",
      "\"drawing\": [\"a\"]\n",
      "}\n",
      "updating pype config file\n",
      "\n",
      "\n",
      "------------+++ new pype iteration 2022-01-17 22:18:57 +++--------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PREPROCESSING\n",
      "blur\n",
      "\n",
      "\n",
      "SEGMENTATION\n",
      "threshold\n",
      "- multichannel image supplied, converting to grayscale\n",
      "- decompose image: using gray channel\n",
      "morphology\n",
      "morphology\n",
      "detect_contour\n",
      "- loaded existing annotation of type \"contour\" with ID \"a\": overwriting (edit=overwrite)\n",
      "- found 99 contours that match criteria\n",
      "edit_contour\n",
      "- loaded existing annotation of type \"drawing\" with ID \"a\": skipping (edit=False)\n",
      "detect_contour\n",
      "- loaded existing annotation of type \"contour\" with ID \"b\": overwriting (edit=overwrite)\n",
      "- found 85 contours that match criteria\n",
      "\n",
      "\n",
      "VISUALIZATION\n",
      "select_canvas\n",
      "- raw image\n",
      "draw_contour\n",
      "\n",
      "\n",
      "MEASUREMENT\n",
      "compute_shape_features\n",
      "\n",
      "\n",
      "EXPORT\n",
      "save_canvas\n",
      "- image saved under D:\\workspace\\git-repos\\phenopype\\phenopype-gallery\\_temp\\project_5\\project\\data\\0__phyto2_BF\\canvas_v1.jpg (overwritten).\n",
      "save_annotation\n",
      "- loading existing annotation file\n",
      "- updating annotation of type \"contour\" with id \"a\" in \"annotations_v1.json\" (overwrite=\"entry\")\n",
      "- updating annotation of type \"contour\" with id \"b\" in \"annotations_v1.json\" (overwrite=\"entry\")\n",
      "- updating annotation of type \"drawing\" with id \"a\" in \"annotations_v1.json\" (overwrite=\"entry\")\n",
      "- writing annotation of type \"shape_features\" with id \"a\" to \"annotations_v1.json\"\n",
      "updating pype config file\n",
      "\n",
      "\n",
      "------------+++ finished pype iteration +++--------------\n",
      "-------(End with Ctrl+Enter or re-run with Enter)--------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "AUTOSAVE\n",
      "- nothing to autosave\n",
      "Format path to abspath\n",
      "- no annotation_type selected - returning all annotations\n",
      "\n",
      "AUTOLOAD\n",
      "- annotations loaded:\n",
      "{\n",
      "\"contour\": [\"a\", \"b\"],\n",
      "\"drawing\": [\"a\"]\n",
      "}\n",
      "updating pype config file\n",
      "\n",
      "\n",
      "------------+++ new pype iteration 2022-01-17 22:18:58 +++--------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PREPROCESSING\n",
      "blur\n",
      "\n",
      "\n",
      "SEGMENTATION\n",
      "threshold\n",
      "- multichannel image supplied, converting to grayscale\n",
      "- decompose image: using gray channel\n",
      "morphology\n",
      "morphology\n",
      "detect_contour\n",
      "- loaded existing annotation of type \"contour\" with ID \"a\": overwriting (edit=overwrite)\n",
      "- found 108 contours that match criteria\n",
      "edit_contour\n",
      "- loaded existing annotation of type \"drawing\" with ID \"a\": skipping (edit=False)\n",
      "detect_contour\n",
      "- loaded existing annotation of type \"contour\" with ID \"b\": overwriting (edit=overwrite)\n",
      "- found 89 contours that match criteria\n",
      "\n",
      "\n",
      "VISUALIZATION\n",
      "select_canvas\n",
      "- raw image\n",
      "draw_contour\n",
      "\n",
      "\n",
      "MEASUREMENT\n",
      "compute_shape_features\n",
      "\n",
      "\n",
      "EXPORT\n",
      "save_canvas\n",
      "- image saved under D:\\workspace\\git-repos\\phenopype\\phenopype-gallery\\_temp\\project_5\\project\\data\\0__phyto3_BF\\canvas_v1.jpg (overwritten).\n",
      "save_annotation\n",
      "- loading existing annotation file\n",
      "- updating annotation of type \"contour\" with id \"a\" in \"annotations_v1.json\" (overwrite=\"entry\")\n",
      "- updating annotation of type \"contour\" with id \"b\" in \"annotations_v1.json\" (overwrite=\"entry\")\n",
      "- updating annotation of type \"drawing\" with id \"a\" in \"annotations_v1.json\" (overwrite=\"entry\")\n",
      "- writing annotation of type \"shape_features\" with id \"a\" to \"annotations_v1.json\"\n",
      "updating pype config file\n",
      "\n",
      "\n",
      "------------+++ finished pype iteration +++--------------\n",
      "-------(End with Ctrl+Enter or re-run with Enter)--------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "AUTOSAVE\n",
      "- nothing to autosave\n"
     ]
    }
   ],
   "source": [
    "## run pype again, but without visual feedback to speed things up\n",
    "## run image processing\n",
    "for path in proj.dir_paths:\n",
    "    pp.Pype(path, tag=\"v1\", feedback=False)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute texture featues of cells in fluorescence images\n",
    "\n",
    "This procedure uses the contour information we collected in the high-throughput workflow above. It provides all object coordinates to the `compute_texture_features` function, which, if also supplied with the fluorescence channel images, extrace texture featues from those coordinates. This code snippet shows that the low-throughput workflow, i.e., writing phenopype functions in pure Python code, can also have its use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- no annotation_type selected - returning all annotations\n",
      "- decompose image: using gray channel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing gray channel texture features: 100%|███████████████████████████████████████| 71/71 [00:00<00:00, 143.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- decompose image: using gray channel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing gray channel texture features: 100%|███████████████████████████████████████| 71/71 [00:00<00:00, 138.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- decompose image: using gray channel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing gray channel texture features: 100%|███████████████████████████████████████| 71/71 [00:00<00:00, 142.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- loading existing annotation file\n",
      "- annotation of type \"contour\" with id \"a\" already exists in \"annotations_v1.json\" (overwrite=False)\n",
      "- annotation of type \"contour\" with id \"b\" already exists in \"annotations_v1.json\" (overwrite=False)\n",
      "- annotation of type \"drawing\" with id \"a\" already exists in \"annotations_v1.json\" (overwrite=False)\n",
      "- annotation of type \"shape_features\" with id \"a\" already exists in \"annotations_v1.json\" (overwrite=False)\n",
      "- writing annotation of type \"texture_features\" with id \"FL1\" to \"annotations_v1.json\"\n",
      "- writing annotation of type \"texture_features\" with id \"FL2\" to \"annotations_v1.json\"\n",
      "- writing annotation of type \"texture_features\" with id \"FL3\" to \"annotations_v1.json\"\n",
      "- no annotation_type selected - returning all annotations\n",
      "- decompose image: using gray channel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing gray channel texture features: 100%|███████████████████████████████████████| 85/85 [00:00<00:00, 142.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- decompose image: using gray channel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing gray channel texture features: 100%|███████████████████████████████████████| 85/85 [00:00<00:00, 139.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- decompose image: using gray channel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing gray channel texture features: 100%|███████████████████████████████████████| 85/85 [00:00<00:00, 140.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- loading existing annotation file\n",
      "- annotation of type \"contour\" with id \"a\" already exists in \"annotations_v1.json\" (overwrite=False)\n",
      "- annotation of type \"contour\" with id \"b\" already exists in \"annotations_v1.json\" (overwrite=False)\n",
      "- annotation of type \"drawing\" with id \"a\" already exists in \"annotations_v1.json\" (overwrite=False)\n",
      "- annotation of type \"shape_features\" with id \"a\" already exists in \"annotations_v1.json\" (overwrite=False)\n",
      "- writing annotation of type \"texture_features\" with id \"FL1\" to \"annotations_v1.json\"\n",
      "- writing annotation of type \"texture_features\" with id \"FL2\" to \"annotations_v1.json\"\n",
      "- writing annotation of type \"texture_features\" with id \"FL3\" to \"annotations_v1.json\"\n",
      "- no annotation_type selected - returning all annotations\n",
      "- decompose image: using gray channel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing gray channel texture features: 100%|███████████████████████████████████████| 89/89 [00:00<00:00, 139.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- decompose image: using gray channel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing gray channel texture features: 100%|███████████████████████████████████████| 89/89 [00:00<00:00, 141.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- decompose image: using gray channel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing gray channel texture features: 100%|███████████████████████████████████████| 89/89 [00:00<00:00, 141.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- loading existing annotation file\n",
      "- annotation of type \"contour\" with id \"a\" already exists in \"annotations_v1.json\" (overwrite=False)\n",
      "- annotation of type \"contour\" with id \"b\" already exists in \"annotations_v1.json\" (overwrite=False)\n",
      "- annotation of type \"drawing\" with id \"a\" already exists in \"annotations_v1.json\" (overwrite=False)\n",
      "- annotation of type \"shape_features\" with id \"a\" already exists in \"annotations_v1.json\" (overwrite=False)\n",
      "- writing annotation of type \"texture_features\" with id \"FL1\" to \"annotations_v1.json\"\n",
      "- writing annotation of type \"texture_features\" with id \"FL2\" to \"annotations_v1.json\"\n",
      "- writing annotation of type \"texture_features\" with id \"FL3\" to \"annotations_v1.json\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for path in proj.dir_paths:\n",
    "    \n",
    "    ## the _load_yaml function is part of the private API, and used here to load the attributes file to get the image name\n",
    "    attributes = pp.utils_lowlevel._load_yaml(os.path.join(path, \"attributes.yaml\"))\n",
    "    image_stem = attributes[\"image_original\"][\"filename\"].partition('_')[0]\n",
    "    \n",
    "    ## we load the annotations collection in the high throughput workflow above - we need the contour coordinates of each object\n",
    "    annotations = pp.export.load_annotation(os.path.join(path, \"annotations_v1.json\"))\n",
    "    \n",
    "    ## we now loop through the files in the data folder, which are named like the brightfield image, and load those images\n",
    "    for channel in [\"FL1\",\"FL2\",\"FL3\"]:\n",
    "        image_fluorescence_path = os.path.join( r\"../../gallery/data\", image_stem + \"_\" + channel + \".tif\")\n",
    "        image_fluorescence = pp.load_image(image_fluorescence_path)\n",
    "        \n",
    "        ## using the fluorescence image and the contours, we can compute texture features for each object. this is somewhat computationally intensive\n",
    "        annotations = pp.measurement.compute_texture_features(image_fluorescence, contour_id=\"b\", annotations=annotations, annotation_id=channel)\n",
    "    \n",
    "    ## we store the textures back to the annotations file\n",
    "    pp.export.save_annotation(annotations, dir_path = path, file_name=\"annotations_v1.json\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created D:\\workspace\\git-repos\\phenopype\\phenopype-gallery\\_temp\\project_5\\project\\results\\annotations\n",
      "Search string: ['annotations_v1']\n",
      "Collected annotations_v1.json from 0__phyto1_BF\n",
      "0__phyto1_BF_annotations_v1.json saved under D:\\workspace\\git-repos\\phenopype\\phenopype-gallery\\_temp\\project_5\\project\\results\\annotations\\0__phyto1_BF_annotations_v1.json.\n",
      "Collected annotations_v1.json from 0__phyto2_BF\n",
      "0__phyto2_BF_annotations_v1.json saved under D:\\workspace\\git-repos\\phenopype\\phenopype-gallery\\_temp\\project_5\\project\\results\\annotations\\0__phyto2_BF_annotations_v1.json.\n",
      "Collected annotations_v1.json from 0__phyto3_BF\n",
      "0__phyto3_BF_annotations_v1.json saved under D:\\workspace\\git-repos\\phenopype\\phenopype-gallery\\_temp\\project_5\\project\\results\\annotations\\0__phyto3_BF_annotations_v1.json.\n"
     ]
    }
   ],
   "source": [
    "proj.collect_results(files=[\"canvas\", \"shape\", \"texture\"], tag=\"v1\", aggregate_csv=True, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
